{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.005902769579486695,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0001180553915897339,
      "grad_norm": 9.122840881347656,
      "learning_rate": 4.999822916912615e-05,
      "loss": 0.7484,
      "step": 10
    },
    {
      "epoch": 0.0002361107831794678,
      "grad_norm": 3.554032802581787,
      "learning_rate": 4.999626157926633e-05,
      "loss": 0.6968,
      "step": 20
    },
    {
      "epoch": 0.0003541661747692017,
      "grad_norm": 9.008957862854004,
      "learning_rate": 4.99942939894065e-05,
      "loss": 0.6278,
      "step": 30
    },
    {
      "epoch": 0.0004722215663589356,
      "grad_norm": 10.59624195098877,
      "learning_rate": 4.999232639954667e-05,
      "loss": 0.5441,
      "step": 40
    },
    {
      "epoch": 0.0005902769579486695,
      "grad_norm": 3.690293550491333,
      "learning_rate": 4.999035880968684e-05,
      "loss": 0.5702,
      "step": 50
    },
    {
      "epoch": 0.0007083323495384034,
      "grad_norm": 13.46773624420166,
      "learning_rate": 4.998839121982701e-05,
      "loss": 0.576,
      "step": 60
    },
    {
      "epoch": 0.0008263877411281373,
      "grad_norm": 9.703500747680664,
      "learning_rate": 4.9986423629967184e-05,
      "loss": 0.5948,
      "step": 70
    },
    {
      "epoch": 0.0009444431327178712,
      "grad_norm": 6.914994716644287,
      "learning_rate": 4.998445604010735e-05,
      "loss": 0.5383,
      "step": 80
    },
    {
      "epoch": 0.0010624985243076052,
      "grad_norm": 6.0601115226745605,
      "learning_rate": 4.998248845024753e-05,
      "loss": 0.6049,
      "step": 90
    },
    {
      "epoch": 0.001180553915897339,
      "grad_norm": 7.377403259277344,
      "learning_rate": 4.99805208603877e-05,
      "loss": 0.5601,
      "step": 100
    },
    {
      "epoch": 0.001298609307487073,
      "grad_norm": 4.145605564117432,
      "learning_rate": 4.9978553270527864e-05,
      "loss": 0.4953,
      "step": 110
    },
    {
      "epoch": 0.0014166646990768068,
      "grad_norm": 4.426718711853027,
      "learning_rate": 4.997658568066804e-05,
      "loss": 0.5831,
      "step": 120
    },
    {
      "epoch": 0.0015347200906665407,
      "grad_norm": 5.646599292755127,
      "learning_rate": 4.997461809080821e-05,
      "loss": 0.5618,
      "step": 130
    },
    {
      "epoch": 0.0016527754822562746,
      "grad_norm": 7.090254306793213,
      "learning_rate": 4.9972650500948384e-05,
      "loss": 0.556,
      "step": 140
    },
    {
      "epoch": 0.0017708308738460085,
      "grad_norm": 10.807452201843262,
      "learning_rate": 4.997068291108855e-05,
      "loss": 0.6284,
      "step": 150
    },
    {
      "epoch": 0.0018888862654357424,
      "grad_norm": 3.1313748359680176,
      "learning_rate": 4.996871532122872e-05,
      "loss": 0.5574,
      "step": 160
    },
    {
      "epoch": 0.0020069416570254765,
      "grad_norm": 7.657373905181885,
      "learning_rate": 4.9966747731368897e-05,
      "loss": 0.5547,
      "step": 170
    },
    {
      "epoch": 0.0021249970486152104,
      "grad_norm": 13.426591873168945,
      "learning_rate": 4.996478014150906e-05,
      "loss": 0.5245,
      "step": 180
    },
    {
      "epoch": 0.0022430524402049443,
      "grad_norm": 7.948470115661621,
      "learning_rate": 4.9962812551649236e-05,
      "loss": 0.6202,
      "step": 190
    },
    {
      "epoch": 0.002361107831794678,
      "grad_norm": 9.029962539672852,
      "learning_rate": 4.99608449617894e-05,
      "loss": 0.5258,
      "step": 200
    },
    {
      "epoch": 0.002479163223384412,
      "grad_norm": 4.356457233428955,
      "learning_rate": 4.995887737192958e-05,
      "loss": 0.5807,
      "step": 210
    },
    {
      "epoch": 0.002597218614974146,
      "grad_norm": 4.425667762756348,
      "learning_rate": 4.995690978206975e-05,
      "loss": 0.5413,
      "step": 220
    },
    {
      "epoch": 0.00271527400656388,
      "grad_norm": 6.8826375007629395,
      "learning_rate": 4.995494219220992e-05,
      "loss": 0.5556,
      "step": 230
    },
    {
      "epoch": 0.0028333293981536137,
      "grad_norm": 11.675673484802246,
      "learning_rate": 4.9952974602350096e-05,
      "loss": 0.5192,
      "step": 240
    },
    {
      "epoch": 0.0029513847897433476,
      "grad_norm": 6.608476161956787,
      "learning_rate": 4.995100701249026e-05,
      "loss": 0.4575,
      "step": 250
    },
    {
      "epoch": 0.0030694401813330815,
      "grad_norm": 3.0381078720092773,
      "learning_rate": 4.9949039422630436e-05,
      "loss": 0.4583,
      "step": 260
    },
    {
      "epoch": 0.0031874955729228154,
      "grad_norm": 5.775074005126953,
      "learning_rate": 4.99470718327706e-05,
      "loss": 0.5964,
      "step": 270
    },
    {
      "epoch": 0.0033055509645125492,
      "grad_norm": 9.25759506225586,
      "learning_rate": 4.9945104242910775e-05,
      "loss": 0.518,
      "step": 280
    },
    {
      "epoch": 0.003423606356102283,
      "grad_norm": 5.416192054748535,
      "learning_rate": 4.994313665305095e-05,
      "loss": 0.4567,
      "step": 290
    },
    {
      "epoch": 0.003541661747692017,
      "grad_norm": 7.702308177947998,
      "learning_rate": 4.9941169063191115e-05,
      "loss": 0.5167,
      "step": 300
    },
    {
      "epoch": 0.003659717139281751,
      "grad_norm": 4.413213729858398,
      "learning_rate": 4.993920147333129e-05,
      "loss": 0.4619,
      "step": 310
    },
    {
      "epoch": 0.0037777725308714848,
      "grad_norm": 9.45944595336914,
      "learning_rate": 4.993723388347146e-05,
      "loss": 0.4908,
      "step": 320
    },
    {
      "epoch": 0.0038958279224612187,
      "grad_norm": 10.461346626281738,
      "learning_rate": 4.9935266293611635e-05,
      "loss": 0.5522,
      "step": 330
    },
    {
      "epoch": 0.004013883314050953,
      "grad_norm": 7.24505615234375,
      "learning_rate": 4.99332987037518e-05,
      "loss": 0.5234,
      "step": 340
    },
    {
      "epoch": 0.0041319387056406864,
      "grad_norm": 4.59113073348999,
      "learning_rate": 4.9931331113891974e-05,
      "loss": 0.582,
      "step": 350
    },
    {
      "epoch": 0.004249994097230421,
      "grad_norm": 5.252359867095947,
      "learning_rate": 4.992936352403215e-05,
      "loss": 0.4751,
      "step": 360
    },
    {
      "epoch": 0.004368049488820154,
      "grad_norm": 4.8921356201171875,
      "learning_rate": 4.9927395934172314e-05,
      "loss": 0.5185,
      "step": 370
    },
    {
      "epoch": 0.0044861048804098885,
      "grad_norm": 4.163811683654785,
      "learning_rate": 4.992542834431249e-05,
      "loss": 0.5931,
      "step": 380
    },
    {
      "epoch": 0.004604160271999622,
      "grad_norm": 2.7670211791992188,
      "learning_rate": 4.9923460754452654e-05,
      "loss": 0.5755,
      "step": 390
    },
    {
      "epoch": 0.004722215663589356,
      "grad_norm": 8.472687721252441,
      "learning_rate": 4.9921493164592834e-05,
      "loss": 0.5331,
      "step": 400
    },
    {
      "epoch": 0.00484027105517909,
      "grad_norm": 5.849053859710693,
      "learning_rate": 4.9919525574733e-05,
      "loss": 0.5724,
      "step": 410
    },
    {
      "epoch": 0.004958326446768824,
      "grad_norm": 5.746109485626221,
      "learning_rate": 4.991755798487317e-05,
      "loss": 0.5229,
      "step": 420
    },
    {
      "epoch": 0.0050763818383585575,
      "grad_norm": 7.014742851257324,
      "learning_rate": 4.991559039501335e-05,
      "loss": 0.4844,
      "step": 430
    },
    {
      "epoch": 0.005194437229948292,
      "grad_norm": 12.505563735961914,
      "learning_rate": 4.9913622805153513e-05,
      "loss": 0.4876,
      "step": 440
    },
    {
      "epoch": 0.005312492621538025,
      "grad_norm": 4.170493125915527,
      "learning_rate": 4.991165521529369e-05,
      "loss": 0.5344,
      "step": 450
    },
    {
      "epoch": 0.00543054801312776,
      "grad_norm": 5.151549339294434,
      "learning_rate": 4.990968762543385e-05,
      "loss": 0.541,
      "step": 460
    },
    {
      "epoch": 0.005548603404717493,
      "grad_norm": 8.91074275970459,
      "learning_rate": 4.9907720035574026e-05,
      "loss": 0.4564,
      "step": 470
    },
    {
      "epoch": 0.005666658796307227,
      "grad_norm": 6.156696796417236,
      "learning_rate": 4.99057524457142e-05,
      "loss": 0.5399,
      "step": 480
    },
    {
      "epoch": 0.005784714187896961,
      "grad_norm": 10.022157669067383,
      "learning_rate": 4.9903784855854366e-05,
      "loss": 0.4675,
      "step": 490
    },
    {
      "epoch": 0.005902769579486695,
      "grad_norm": 3.782085657119751,
      "learning_rate": 4.990181726599454e-05,
      "loss": 0.504,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 254118,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 526226835456000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
